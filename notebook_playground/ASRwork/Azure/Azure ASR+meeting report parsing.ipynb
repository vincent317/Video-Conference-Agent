{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "68ed9ab8",
   "metadata": {},
   "source": [
    "### Load enviornment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933a14f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pathlib\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "58ca6a01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set environment variables\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "env_path = Path('.') / '.env'\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce16de06",
   "metadata": {},
   "source": [
    "## 3. Start building meeting report json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2167757",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyjwt\n",
    "!pip install webvtt-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2373591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwt\n",
    "import requests\n",
    "import json\n",
    "from time import time\n",
    "import os\n",
    "import webvtt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4d0f093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a token using the pyjwt library\n",
    "token = jwt.encode(\n",
    "\n",
    "    # Create a payload of the token containing\n",
    "    # API Key & expiration time\n",
    "    {'iss': os.getenv('ZOOM_API_KEY'), 'exp': time() + 5000},\n",
    "\n",
    "    # Secret used to generate token signature\n",
    "    os.getenv('ZOOM_API_SEC'),\n",
    "\n",
    "    # Specify the hashing alg\n",
    "    algorithm='HS256'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dd0ceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input required from user\n",
    "# For Sp23, use meeting_id being the main input and Dummy User Input for parsing purpose\n",
    "meeting_id = 85760048922\n",
    "\n",
    "## DUMMY USER INPUT\n",
    "meeting_title = \"23min_demo_meeting\"\n",
    "meeting_date = '2023-03-03T19:59:40Z'\n",
    "meeting_participants_count = 3\n",
    "agenda_list = [\"Duke and Duchess of Sussex asked to vacate UK home Frogmore Cottage\", \n",
    "               \"Alex Muradugh guilty\",\n",
    "               \"Data Center Trends\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1901ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meeting participants\n",
    "# as if start_time is 2023-03-03T19:59:40Z\n",
    "from datetime import datetime as dt\n",
    "parsed_meeting_date = dt.strptime(meeting_date, '%Y-%m-%dT%H:%M:%SZ').strftime('%Y-%m-%d %H:%M:%S')\n",
    "headers = {'authorization': 'Bearer %s' % token, 'content-type': 'application/json'}\n",
    "part = requests.get(f'https://api.zoom.us/v2/past_meetings/'+str(meeting_id)+'/participants', headers=headers)\n",
    "part_info = {}\n",
    "if part.status_code == 200:\n",
    "    response = json.loads(part.text)\n",
    "    part_arr = response['participants']\n",
    "    \n",
    "    for p in part_arr:\n",
    "        part_info[p['name']] = {'late': 'late' if dt.strptime(p['join_time'], '%Y-%m-%dT%H:%M:%SZ') > dt.strptime(meeting_date, '%Y-%m-%dT%H:%M:%SZ') else 'on-time'}\n",
    "\n",
    "###### WILL NOT GET INCLUDED IN FINAL OUTPUT ######        \n",
    "# change dazhi's name in p_detail as it's in email :/\n",
    "part_info['DAZHI PENG'] = part_info.pop('dazhip@andrew.cmu.edu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2a13997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start setting up meeting_report_json\n",
    "from datetime import datetime as dt\n",
    "meeting_report_json = {}\n",
    "\n",
    "meeting_report_json['meeting_title'] = meeting_title\n",
    "\n",
    "meeting_report_json['meeting_date'] = parsed_meeting_date\n",
    "\n",
    "meeting_report_json['participants'] = part_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1d8142c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_title': '23min_demo_meeting',\n",
       " 'meeting_date': '2023-03-03 19:59:40',\n",
       " 'participants': {'Yooni Choi': {'late': 'on-time'},\n",
       "  'Jiahe Feng': {'late': 'late'},\n",
       "  'DAZHI PENG': {'late': 'late'}}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_report_json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e42573a5",
   "metadata": {},
   "source": [
    "## 4. ASR Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7733e2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# requirements\n",
    "# ffmpeg\n",
    "\n",
    "!pip install azure-storage-blob\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5587eb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32512"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert to supported format\n",
    "# have to think about how we are going to use ffmpeg\n",
    "# currently, I've downloaded ffmpeg on my local machine\n",
    "import os\n",
    "zoom_m4a = \"85760048922_M4A.m4a\"\n",
    "out_wav = \"out.wav\"\n",
    "os.system(\"ffmpeg -i {0} -acodec pcm_s16le -ac 1 -ar 16000 {1}\".format(zoom_m4a, out_wav))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f41a0ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/21/2023 11:13:58 AM EDT Request URL: 'https://vcademo.blob.core.windows.net/vcademo/out.wav'\n",
      "Request method: 'PUT'\n",
      "Request headers:\n",
      "    'Content-Length': '44458062'\n",
      "    'x-ms-blob-type': 'REDACTED'\n",
      "    'If-None-Match': '*'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'Content-Type': 'application/octet-stream'\n",
      "    'Accept': 'application/xml'\n",
      "    'User-Agent': 'azsdk-python-storage-blob/12.15.0 Python/3.8.8 (macOS-10.16-x86_64-i386-64bit)'\n",
      "    'x-ms-date': 'REDACTED'\n",
      "    'x-ms-client-request-id': '23f31318-e057-11ed-bcee-acde48001122'\n",
      "    'Authorization': 'REDACTED'\n",
      "A body is sent with the request\n",
      "04/21/2023 11:14:03 AM EDT Response status: 201\n",
      "Response headers:\n",
      "    'Content-Length': '0'\n",
      "    'Content-MD5': 'REDACTED'\n",
      "    'Last-Modified': 'Fri, 21 Apr 2023 15:14:06 GMT'\n",
      "    'ETag': '\"0x8DB427B0D01FB50\"'\n",
      "    'Server': 'Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0'\n",
      "    'x-ms-request-id': '6f10e22a-001e-0081-1763-74be6c000000'\n",
      "    'x-ms-client-request-id': '23f31318-e057-11ed-bcee-acde48001122'\n",
      "    'x-ms-version': 'REDACTED'\n",
      "    'x-ms-content-crc64': 'REDACTED'\n",
      "    'x-ms-request-server-encrypted': 'REDACTED'\n",
      "    'Date': 'Fri, 21 Apr 2023 15:14:06 GMT'\n",
      "Uploaded out.wav.\n"
     ]
    }
   ],
   "source": [
    "# upload .wav file to azure blob\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "\n",
    "storage_account_key = os.getenv('AUDIO_STORAGE_ACCT_KEY')\n",
    "storage_account_name = os.getenv('AUDIO_STORAGE_ACCT_NAME')\n",
    "connection_string = os.getenv('CONNECTION_STRING')\n",
    "container_name = os.getenv('AUDIO_CONTAINER_NAME')\n",
    "\n",
    "def uploadToBlobStorage(file_path,file_name):\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    blob_client = blob_service_client.get_blob_client(container=container_name, blob=file_name)\n",
    "    with open(file_path, \"rb\") as data:\n",
    "        blob_client.upload_blob(data)\n",
    "        print(f\"Uploaded {file_name}.\")\n",
    "\n",
    "# calling a function to perform upload\n",
    "audio_path = \"/Users/yooni/Desktop/vca_data/\" + out_wav\n",
    "audio_name = out_wav\n",
    "uploadToBlobStorage(audio_path, audio_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e26830c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://vcademo.blob.core.windows.net/vcademo/out.wav?se=2023-04-21T16%3A14%3A08Z&sp=r&sv=2021-12-02&sr=b&sig=iNr35mtO914DyP4Y3tQ4BUujLb1uLMaDJH6vh3KoYJ8%3D'"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS CELL IS NOT WORKING IDK WHY ##\n",
    "# get blob SAS url\n",
    "from datetime import datetime, timedelta\n",
    "from azure.storage.blob import BlobClient, generate_blob_sas, BlobSasPermissions\n",
    "\n",
    "\n",
    "blob_name = audio_name\n",
    "\n",
    "def get_blob_sas(storage_account_name, storage_account_key, container_name, blob_name):\n",
    "    sas_blob = generate_blob_sas(account_name=storage_account_name, \n",
    "                                container_name=container_name,\n",
    "                                blob_name=blob_name,\n",
    "                                account_key=storage_account_key,\n",
    "                                permission=BlobSasPermissions(read=True),\n",
    "                                expiry=datetime.utcnow() + timedelta(hours=1))\n",
    "    return sas_blob\n",
    "\n",
    "blob_token = get_blob_sas(storage_account_name, storage_account_key, container_name, blob_name)\n",
    "blob_sas_url = 'https://'+storage_account_name+'.blob.core.windows.net/'+container_name+'/'+blob_name+'?'+blob_token\n",
    "blob_sas_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "acd7b20f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://vcatranscriptions.blob.core.windows.net/transcription-results?se=2023-04-21T16%3A14%3A13Z&sp=rwl&sv=2021-12-02&sr=c&sig=d5Io6V6/W05ma/WD0NKJtUHMwx0sRCL%2BKla4Ks65esU%3D'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# THIS CELL IS NOT WORKING IDK WHY ##\n",
    "# set up transcription result container sas\n",
    "transcription_stroage_account_key = os.getenv('TRANSCRIPTION_STORAGE_ACCT_KEY')\n",
    "transcription_stroage_account_name = os.getenv('TRANSCRIPTION_STORAGE_ACCT_NAME')\n",
    "transcription_container_name = os.getenv('TRANSCRIPTION_CONTAINER_NAME')\n",
    "from azure.storage.blob import generate_container_sas, ContainerSasPermissions\n",
    "def get_container_sas(storage_account_name, storage_account_key, container_name):\n",
    "    container_sas = generate_container_sas(\n",
    "       account_name=storage_account_name,\n",
    "       container_name=container_name,\n",
    "       account_key=storage_account_key,\n",
    "       permission=ContainerSasPermissions(write=True, read=True, list=True),\n",
    "       start = datetime.utcnow(),\n",
    "       expiry=datetime.utcnow() + timedelta(hours=1))\n",
    "    return container_sas\n",
    "container_token = get_container_sas(storage_account_name, storage_account_key, transcription_container_name)\n",
    "container_sas_url = 'https://'+transcription_stroage_account_name+'.blob.core.windows.net/'+transcription_container_name+'?'+container_token\n",
    "container_sas_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e7c8d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ###### Not going to be in final code ######\n",
    "# # placeholder SAS for now\n",
    "# # sas url with 1yr expiry -- transcription container should be different container from audio blob storage since it requires all external traffic allowed\n",
    "# blob_sas_url = os.getenv('TEMP_BLOB_SAS_URL')\n",
    "# container_sas_url = os.getenv('TEMP_CONTAINER_SAS_URL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01489bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./python-client\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from swagger-client==1.0.0) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from swagger-client==1.0.0) (2.8.1)\n",
      "Requirement already satisfied: six>=1.10 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from swagger-client==1.0.0) (1.15.0)\n",
      "Requirement already satisfied: urllib3>=1.23 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from swagger-client==1.0.0) (1.26.12)\n",
      "Building wheels for collected packages: swagger-client\n",
      "  Building wheel for swagger-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for swagger-client: filename=swagger_client-1.0.0-py3-none-any.whl size=221566 sha256=605a6868f631db5eb1eaea3953124cda5c8caee00ed1f5a346acc7eb548fc712\n",
      "  Stored in directory: /Users/yooni/Library/Caches/pip/wheels/f5/1f/0a/fa0cd5a2204b8564b5bca2e85cbb0efd152c039fc2213d07a9\n",
      "Successfully built swagger-client\n",
      "Installing collected packages: swagger-client\n",
      "  Attempting uninstall: swagger-client\n",
      "    Found existing installation: swagger-client 1.0.0\n",
      "    Uninstalling swagger-client-1.0.0:\n",
      "      Successfully uninstalled swagger-client-1.0.0\n",
      "Successfully installed swagger-client-1.0.0\n"
     ]
    }
   ],
   "source": [
    "# setting up Swagger\n",
    "!pip install /Users/yooni/Desktop/CMU/Capstone/Video-Conference-Agent/notebook_playground/ASRwork/Azure/python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b94c9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (2.25.1)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from requests) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from requests) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/yooni/opt/anaconda3/lib/python3.8/site-packages (from requests) (2020.12.5)\n"
     ]
    }
   ],
   "source": [
    "!python -c \"import swagger_client\"\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "88f360ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your subscription key and region for the speech service\n",
    "SUBSCRIPTION_KEY = os.getenv('SPEECH_SUBSCRIPTION_KEY')   # use vca-speech-resource since it doesnt support Free tier\n",
    "SERVICE_REGION = \"eastus\"\n",
    "NAME = meeting_title\n",
    "DESCRIPTION = parsed_meeting_date + ' '+ meeting_title + ' transcription'\n",
    "LOCALE = \"en-US\"\n",
    "RECORDINGS_BLOB_URI = blob_sas_url\n",
    "PARTICIPANT_COUNT = meeting_participants_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0d30cef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import requests\n",
    "import time\n",
    "import swagger_client\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG,\n",
    "        format=\"%(asctime)s %(message)s\", datefmt=\"%m/%d/%Y %I:%M:%S %p %Z\")\n",
    "\n",
    "\n",
    "# # Provide the uri of a container with audio files for transcribing all of them\n",
    "# # with a single request. At least 'read' and 'list' (rl) permissions are required.\n",
    "# RECORDINGS_CONTAINER_URI = \"<Your SAS Uri to a container of audio files>\"\n",
    "\n",
    "\n",
    "def transcribe_from_single_blob(uri, properties):\n",
    "    \"\"\"\n",
    "    Transcribe a single audio file located at `uri` using the settings specified in `properties`\n",
    "    using the base model for the specified locale.\n",
    "    \"\"\"\n",
    "    transcription_definition = swagger_client.Transcription(\n",
    "        display_name=NAME,\n",
    "        description=DESCRIPTION,\n",
    "        locale=LOCALE,\n",
    "        content_urls=[uri],\n",
    "        properties=properties\n",
    "    )\n",
    "\n",
    "    return transcription_definition\n",
    "\n",
    "def _paginate(api, paginated_object):\n",
    "    \"\"\"\n",
    "    The autogenerated client does not support pagination. This function returns a generator over\n",
    "    all items of the array that the paginated object `paginated_object` is part of.\n",
    "    \"\"\"\n",
    "    yield from paginated_object.values\n",
    "    typename = type(paginated_object).__name__\n",
    "    auth_settings = [\"api_key\"]\n",
    "    while paginated_object.next_link:\n",
    "        link = paginated_object.next_link[len(api.api_client.configuration.host):]\n",
    "        paginated_object, status, headers = api.api_client.call_api(link, \"GET\",\n",
    "            response_type=typename, auth_settings=auth_settings)\n",
    "\n",
    "        if status == 200:\n",
    "            yield from paginated_object.values\n",
    "        else:\n",
    "            raise Exception(f\"could not receive paginated data: status {status}\")\n",
    "\n",
    "def transcribe():\n",
    "    logging.info(\"Starting transcription client...\")\n",
    "\n",
    "    # configure API key authorization: subscription_key\n",
    "    configuration = swagger_client.Configuration()\n",
    "    configuration.api_key[\"Ocp-Apim-Subscription-Key\"] = SUBSCRIPTION_KEY\n",
    "    configuration.host = f\"https://{SERVICE_REGION}.api.cognitive.microsoft.com/speechtotext/v3.1\"\n",
    "\n",
    "    # create the client object and authenticate\n",
    "    client = swagger_client.ApiClient(configuration)\n",
    "\n",
    "    # create an instance of the transcription api class\n",
    "    api = swagger_client.CustomSpeechTranscriptionsApi(api_client=client)\n",
    "\n",
    "    # Specify transcription properties by passing a dict to the properties parameter. See\n",
    "    # https://learn.microsoft.com/azure/cognitive-services/speech-service/batch-transcription-create?pivots=rest-api#request-configuration-options\n",
    "    # for supported parameters.\n",
    "    properties = swagger_client.TranscriptionProperties()\n",
    "    # properties.word_level_timestamps_enabled = True\n",
    "    properties.display_form_word_level_timestamps_enabled = True\n",
    "    properties.punctuation_mode = \"DictatedAndAutomatic\"\n",
    "    # properties.profanity_filter_mode = \"Masked\"\n",
    "    properties.destination_container_url = container_sas_url\n",
    "\n",
    "    # uncomment the following block to enable and configure speaker separation\n",
    "    properties.diarization_enabled = True\n",
    "    properties.diarization = swagger_client.DiarizationProperties(\n",
    "        swagger_client.DiarizationSpeakersProperties(min_count=1, max_count=PARTICIPANT_COUNT))\n",
    "\n",
    "    # properties.language_identification = swagger_client.LanguageIdentificationProperties([\"en-US\", \"ja-JP\"])\n",
    "\n",
    "    # Use base models for transcription. Comment this block if you are using a custom model.\n",
    "    transcription_definition = transcribe_from_single_blob(RECORDINGS_BLOB_URI, properties)\n",
    "\n",
    "\n",
    "    created_transcription, status, headers = api.transcriptions_create_with_http_info(transcription=transcription_definition)\n",
    "\n",
    "    # get the transcription Id from the location URI\n",
    "    transcription_id = headers[\"location\"].split(\"/\")[-1]\n",
    "\n",
    "    # Log information about the created transcription. If you should ask for support, please\n",
    "    # include this information.\n",
    "    logging.info(f\"Created new transcription with id '{transcription_id}' in region {SERVICE_REGION}\")\n",
    "\n",
    "    logging.info(\"Checking status.\")\n",
    "\n",
    "    completed = False\n",
    "\n",
    "    while not completed:\n",
    "        # wait for 5 seconds before refreshing the transcription status\n",
    "        time.sleep(5)\n",
    "\n",
    "        transcription = api.transcriptions_get(transcription_id)\n",
    "        logging.info(f\"Transcriptions status: {transcription.status}\")\n",
    "\n",
    "        if transcription.status in (\"Failed\", \"Succeeded\"):\n",
    "            completed = True\n",
    "\n",
    "        if transcription.status == \"Succeeded\":\n",
    "            pag_files = api.transcriptions_list_files(transcription_id)\n",
    "            for file_data in _paginate(api, pag_files):\n",
    "                if file_data.kind != \"Transcription\":\n",
    "                    continue\n",
    "\n",
    "                audiofilename = file_data.name\n",
    "                results_url = file_data.links.content_url\n",
    "                results = requests.get(results_url)\n",
    "                logging.info(f\"Results for {audiofilename}:\\n{results.content.decode('utf-8')}\")\n",
    "                return results\n",
    "        elif transcription.status == \"Failed\":\n",
    "            logging.info(f\"Transcription failed: {transcription.properties.error.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "24848439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/21/2023 11:14:35 AM EDT Starting transcription client...\n",
      "04/21/2023 11:14:36 AM EDT Created new transcription with id '6c33e888-9ec3-4d31-bb8a-4be5d553d49f' in region eastus\n",
      "04/21/2023 11:14:36 AM EDT Checking status.\n",
      "04/21/2023 11:14:41 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:14:46 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:14:52 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:14:57 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:02 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:07 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:12 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:17 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:22 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:28 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:33 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:38 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:43 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:48 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:53 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:15:58 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:04 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:09 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:14 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:19 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:24 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:29 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:35 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:40 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:45 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:50 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:16:56 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:01 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:06 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:11 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:16 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:21 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:26 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:31 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:37 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:42 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:47 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:52 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:17:57 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:03 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:08 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:13 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:18 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:24 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:29 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:34 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:39 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:45 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:50 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:18:55 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:00 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:06 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:11 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:16 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:21 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:27 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:32 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:37 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:42 AM EDT Transcriptions status: Running\n",
      "04/21/2023 11:19:48 AM EDT Transcriptions status: Failed\n",
      "04/21/2023 11:19:48 AM EDT Transcription failed: Could not access the results container.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'content'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-148-488e41f6ccac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# run transcription job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranscribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'content'"
     ]
    }
   ],
   "source": [
    "# run transcription job\n",
    "results = transcribe()\n",
    "content = results.content.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5e102b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse transcription results\n",
    "import json\n",
    "import datetime as dt\n",
    "result = json.loads(content)\n",
    "\n",
    "start_date = dt.datetime.strptime(result[\"timestamp\"], '%Y-%m-%dT%H:%M:%SZ')\n",
    "transcription = ''\n",
    "# transcription_timestamp = ''\n",
    "duration = {'total':0}\n",
    "for segment in result[\"recognizedPhrases\"]:\n",
    "    timestamp = start_date + dt.timedelta(seconds =segment[\"offsetInTicks\"]/10000000)\n",
    "    # transcription_timestamp += str(timestamp) + ' Speaker ' + str(segment[\"speaker\"]) + '\\n' + segment[\"nBest\"][0][\"display\"] + '\\n\\n'\n",
    "    transcription += ' Speaker ' + str(segment[\"speaker\"]) + ': ' + segment[\"nBest\"][0][\"display\"] + '\\n\\n'\n",
    "    speaker_duration = segment['durationInTicks']/10000000\n",
    "    if 'Speaker '+ str(segment[\"speaker\"]) not in duration:\n",
    "        duration['Speaker '+ str(segment[\"speaker\"])] = speaker_duration\n",
    "    else:\n",
    "        duration['Speaker '+ str(segment[\"speaker\"])] += speaker_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d4d4a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write transcription.txt files\n",
    "with open('transcription.txt', 'w') as f:\n",
    "    f.write(transcription)\n",
    "\n",
    "# with open('transcription_timestamp.txt', 'w') as f:\n",
    "#     f.write(transcription_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ab9a5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# participant matching\n",
    "import os\n",
    "import requests\n",
    "import openai\n",
    "\n",
    "zoom_transript_path = \"85760048922_TRANSCRIPT.vtt\"\n",
    "asr_transcription_path = \"transcription.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "590441f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_transcript(transcript_file, num_participant, num_line_threshold = 3):\n",
    "    \"\"\"Parse a transcript file and extract conversation text from each participant.\n",
    "\n",
    "    Args:\n",
    "        transcript_file (str): Path to the transcript file.\n",
    "        num_participant (int): Number of participants in the conversation.\n",
    "        num_line_threshold (int, optional): Number of conversation lines from each participant\n",
    "            used for further matching. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        str: A concatenated string of the extracted conversation text from each participant.\n",
    "\n",
    "    Raises:\n",
    "        FileNotFoundError: If the transcript file path is invalid.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def end_transcript_loop(ppt_length):\n",
    "        return len(ppt_length) == 3 and all([v > 100 for v in ppt_length.values()])\n",
    "    \n",
    "    with open(transcript_file) as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    ppt_text = {}\n",
    "    ppt_length = {}\n",
    "\n",
    "    for line in lines:\n",
    "        if \": \" not in line:\n",
    "            continue\n",
    "        line_split = line.split(\": \")\n",
    "        speaker, text = line_split[0], line_split[1]\n",
    "        if speaker in ppt_length and ppt_length[speaker] > num_line_threshold:\n",
    "            continue\n",
    "        if speaker not in ppt_text:\n",
    "            ppt_text[speaker] = text\n",
    "        else:\n",
    "            ppt_text[speaker] += text\n",
    "        if speaker not in ppt_length:\n",
    "            ppt_length[speaker] = 1\n",
    "        else:\n",
    "            ppt_length[speaker] += 1\n",
    "        if end_transcript_loop(ppt_length):\n",
    "            break\n",
    "    result_text = \"\"\n",
    "    for k, v in ppt_text.items():\n",
    "        result_text += k + \": \\n\"\n",
    "        result_text += v + \"\\n\"\n",
    "    return result_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afc27283",
   "metadata": {},
   "outputs": [],
   "source": [
    "zoom_result_text = parse_transcript(zoom_transript_path, 3)\n",
    "azure_result_text = parse_transcript(asr_transcription_path, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "50b26743",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "url = 'https://api.openai.com/v1/chat/completions'\n",
    "headers = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + API_KEY}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c5fa7dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppt_matching_api_call(ASR_transcript, Zoom_transcript):\n",
    "    \n",
    "    # combine two transcript\n",
    "    combined_text = \"Transcript 1: \\n\" + ASR_transcript + \"\\nTranscript 2: \\n\" + Zoom_transcript\n",
    "    \n",
    "    prompt = \"Given the following two transcript with different speaker representation, generate a JSON mapping, where each key is the participant in the first transcript, and the value is the corresponding participant name in the second transcript. Return the JSON only.\"\n",
    "    data = {\n",
    "        \"model\": \"gpt-3.5-turbo\",\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"Perform participant matching and return a JSON\"},\n",
    "            {\"role\": \"assistant\", \"content\": combined_text},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        \"temperature\": 0\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, json=data)\n",
    "    if response.status_code == 200:\n",
    "        content = response.json()\n",
    "        mapping = eval(content['choices'][0]['message']['content'])\n",
    "        if isinstance(mapping, dict):\n",
    "            return mapping\n",
    "        else:\n",
    "            return ValueError(\"Error in GPT participant matching. Must return a dictionary mapping in its response.\")\n",
    "    else:\n",
    "        raise ValueError(\"Fail to get GPT API response.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a53e7c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write new transcription.txt files with speaker names\n",
    "import re\n",
    "ppt_match = ppt_matching_api_call(zoom_result_text, azure_result_text)\n",
    "\n",
    "for k,i in ppt_match.items():\n",
    "    transcription = re.sub(i,k, transcription)\n",
    "\n",
    "# match name to duration dictionary\n",
    "duration = {y:x for x,y in {duration.get(k, k): v for v, k in ppt_match.items()}.items()}\n",
    "duration['total'] = sum(duration.values())\n",
    "    \n",
    "\n",
    "with open('transcription.txt', 'w') as f:\n",
    "    f.write(transcription)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9401ad63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Yooni Choi': 424.4,\n",
       " 'Jiahe Feng': 458.4400000000001,\n",
       " 'DAZHI PENG': 405.6800000000001,\n",
       " 'total': 1288.5200000000002}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4ea8fba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for participant in meeting_report_json['participants']:\n",
    "    if participant in duration:\n",
    "        meeting_report_json['participants'][participant]['duration'] = str(round(duration[participant],2))+'s (' + str(round(duration[participant]/duration['total']*100, 2))+'%)'\n",
    "    else:\n",
    "        meeting_report_json['participants'][participant]['duration'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e2ba55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'meeting_title': '23min_demo_meeting',\n",
       " 'meeting_date': '2023-03-03 19:59:40',\n",
       " 'participants': {'Yooni Choi': {'late': 'on-time',\n",
       "   'duration': '424.4s (32.94%)'},\n",
       "  'Jiahe Feng': {'late': 'late', 'duration': '458.44s (35.58%)'},\n",
       "  'DAZHI PENG': {'late': 'late', 'duration': '405.68s (31.48%)'}}}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meeting_report_json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
