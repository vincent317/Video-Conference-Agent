{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2aa82869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import openai\n",
    "import webvtt\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b70e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ[\"OPENAI_API_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e7e9b",
   "metadata": {},
   "source": [
    "# Proproces the transcripts and define the action items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb72c2f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35bdf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vincent: Hi, Jeffrey, and you need let's talk about the data screening project that you guys have of the project coming along.\\nJeffrey Feng: Hi, do you?\\nJeffrey Feng: We are a bit stuck with scraping some of the websites on our list. Some of them are dynamic, and I couldn't get the data we need.\\nYooni Choi: Yeah, and i'm new to this tax. So I was wondering if you could help us out.\\nVincent: Of course I will be happy to help. What specifically do you need help with.\\nJeffrey Feng: Well, many websites seem dynamic.\\nJeffrey Feng: so I was not able to figure out what to do if you scrape them. I used a few python libraries, but they are not returning me. What I want\\nVincent: have you read into the library?\\nJeffrey Feng: I have not.\\nVincent: Selenium is a software, testing framework used to all the main web browsers. They can similarly user interactions with with the website and from automated testing to check for error\\nVincent: performance issues and functionality twice for some of the website you were talking about.\\nJeffrey Feng: Sure, my first action item will be\\nJeffrey Feng: to read Selenium's documentation, then\\nYooni Choi: so, Jeffrey, have you been using the beautiful soup library.\\nJeffrey Feng: Yes, that's one of the Python libraries that I've been using.\\nYooni Choi: I kept having installation issues. I don't know what is the issue. My, My my python version might be too old.\\nJeffrey Feng: I'll help you with that. I guess another of my action item would be to help you with installation issues.\\nJeffrey Feng: Could you update your python environment before that\\nYooni Choi: that'd be great. Thank you. I'll update my python environment as my action. Item.\\nVincent: Well, you are waiting for Jeffrey to help you. I think you can read it in your beautiful soups. Documentation\\nYooni Choi: sounds good to me. I will make sure to read beautiful Soups documentation as my second action. Item.\\nVincent: Good, Jeffrey, could you create a kid up branch? So we can. In fact, the progress of this project.\\nJeffrey Feng: Sure, I can do that. My new action item is to create a Github branch. Then\\nVincent: another action item for both of you, Jeffrey, and a unique is to report the progress tomorrow to me again.\\nJeffrey Feng: Sure\\nYooni Choi: sounds good to me, Jeffrey. Could we schedule a meeting later? So you can explain your previous code to me. I want to make sure I understand it.\\nJeffrey Feng: Yeah, that sounds good. I will schedule a meeting with you as another action item of my\\nVincent: all right, great. And for Touches action. Item, I will also add a new member to our team to help us with this project.\\nVincent: I will send you all updating a week.\\nYooni Choi: Thanks, Dr.\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd02788",
   "metadata": {},
   "outputs": [],
   "source": [
    "agenda_items = \"1. Duke and Duchess of Sussex asked to vacate UK home Frogmore Cottage.\\\n",
    "2. Alex Muradugh guilty.\\\n",
    "3. Data Centers Intro/definition and origins/size, density and efficiency growth.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbfccd",
   "metadata": {},
   "source": [
    "# Using langchain to break our meeting transcript into chunks and call OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-0301\", openai_api_key = API_KEY)\n",
    "\n",
    "source_chunks = []\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "for chunk in splitter.split_text(everything):\n",
    "    source_chunks.append(Document(page_content=chunk))\n",
    "search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(openai_api_key = API_KEY))\n",
    "\n",
    "chain = load_qa_chain(llm)\n",
    "\n",
    "def print_answer(question):\n",
    "    print(\n",
    "        chain(\n",
    "            {\n",
    "                \"input_documents\": search_index.similarity_search(question, k=4),\n",
    "                \"question\": question,\n",
    "            },\n",
    "            return_only_outputs=True,\n",
    "        )[\"output_text\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99344d",
   "metadata": {},
   "source": [
    "# Action items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f6de91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dazhi Peng needs to work on the details of how much was paid for the renovation of Frogmore Cottage and present it at the next meeting. 2. Jiahe Feng needs to prepare a summary of Alex Murdough's charges and verdicts and have it ready within a week. 3. Jiahe Feng needs to prepare a diagram of the Lyrical design of data centers and share it with the team.\n"
     ]
    }
   ],
   "source": [
    "print_answer(\"Given the agenda items in this meeting transcript: \" + agenda_items + \"Can you identify the action items related to each of them?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727620fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Finalize how much was paid for the refurbishment of Rockmore Cottage (DAZHI PENG and Jiahe Feng).\n",
      "2. Prepare a brief diagram of the design of a data center (DAZHI PENG).\n",
      "3. Watch a show and share thoughts on it (Jiahe Feng). \n",
      "4. Provide a summary of Alex Myrtle's charges and verdicts in a week (DAZHI PENG).\n"
     ]
    }
   ],
   "source": [
    "print_answer(\"What are the action items in this meeting transcript?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904ad7f",
   "metadata": {},
   "source": [
    "# Agenda items\n",
    "ChatGPT can provide a very good summary of the content related to a specific agenda item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "779d422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes. Yooni Choi mentions being busy with cloud work that is still ongoing and discusses the importance of understanding the physical resources that make up the cloud when programming for it. Jiahe Feng talks about the advancements in processing power, memory, and storage in data centers, as well as the increasing power and cooling requirements for large data centers. They do not go into great detail about specific cloud computing topics or projects they are working on.\n"
     ]
    }
   ],
   "source": [
    "print_answer(\"Can you provide more detail in this meeting transcript related to the cloud computing agenda item?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8b329",
   "metadata": {},
   "source": [
    "# (Deprecated) Demo Test using OpenAI Native API\n",
    "Failed because each input can only accept at most 4096 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26fb4738",
   "metadata": {},
   "outputs": [],
   "source": [
    "vtt_file = 'transcripts/A4_techNews.vtt'\n",
    "everything = \"\"\n",
    "for caption in webvtt.read(vtt_file):\n",
    "    everything += caption.text + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14364165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DAZHI PENG: Hi, Kyas, you're asking, although they can, using, checking the free going on this week.\\nJeffrey Feng: Yeah, some are exciting. Some are depressing. The exciting news is that open AI. Release its latest multi-model Gbd: 4 model.\\nJeffrey Feng: Well, that's capable than you lose in many real world scenarios\\nJeffrey Feng: exhibits human level performance on various professional and academic benchmarks. For example, it passes a simulated bar exam with the score around the top. 10% of test acres in contrast. Gbd 3.5 score was around the bottom 10%.\\nYooni Choi: This was so exciting. Can't imagine what youpt for can do, since Chat ipt is so powerful Already I have been using Chat to extensively for my everyday work.\\nDAZHI PENG: Gb. Detroit is so powerful, according to open I Ivd. For the CD. In the most recent public available task is a case of Olympics and ap free response questions. or by producing 2,022 to 2023 patients of pricing them and they they know specifically training for this series.\\nJeffrey Feng: Yeah, I think what's more exciting, that Gpd: 4 can even accept visual. Input\\nJeffrey Feng: There was an example on opening a website that the user asks: what's funny about this image? Describe it panel by panel and Gbd. For successfully identify all the interesting features of that image.\\nYooni Choi: Given these features, I think it's definitely worthwhile for us to do a deep dive into its capabilities. Dr. Would you be able to take on the action? Item, to read open AI's technical report for Gpt for and present a summary of it to the team.\\nDAZHI PENG: Well, i'm pretty pleased this week, so I don't think I could.\\nJeffrey Feng: That's fine. I'll take it\\nJeffrey Feng: at the same time the bad news in the tech industry. It that matter started another round of layoff last\\nJeffrey Feng: November.\\nJeffrey Feng: I think Matt, are plan to lay off are about\\nJeffrey Feng: 10,000 employees, or, roughly, 13% of his workforce.\\nYooni Choi: That's a lot of people I remember Meta already laid off 10,000 employees last year. The layoffs will affect me as recording team this week, with a rec restructuring of his tech and business groups to come in April and May, Mr. Zuckerberg said in a memo posted on the company's website.\\nDAZHI PENG: I also heard it lay up. We involve a lot of let me do layer management people.\\nDAZHI PENG: Oh, my\\nJeffrey Feng: yeah, this is an interesting question for us to investigate as well\\nJeffrey Feng: whether too much middle management people are actually helping or hurting the company.\\nYooni Choi: It makes sense because Meta has kept changing from members to AI, or vice versa. There is definitely something wrong with their leadership structure\\nDAZHI PENG: there you need when nicely would you like to work on\\nDAZHI PENG: Maxine? I'm, curiously whether the middle management layer is helping\\nDAZHI PENG: more slow in the\\nYooni Choi: No. I think we don't need to do so. I think it's just too much work.\\nJeffrey Feng: Yeah, let's just not do it. Anyway, this is an interesting discussion. Have a good week guys.\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fd30f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'Extract action items from this meeting transcript.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ed95360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. DAZHI PENG was asked to read Open AI's technical report for Gpt for and present a summary of it to the team.\n",
      "2. There were no action items assigned for investigating whether too much middle management people are actually helping or hurting the company.\n"
     ]
    }
   ],
   "source": [
    "url = 'https://api.openai.com/v1/chat/completions'\n",
    "headers = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + API_KEY}\n",
    "data = {\n",
    "  \"model\": \"gpt-3.5-turbo\",\n",
    "  \"messages\": [\n",
    "      {\"role\": \"system\", \"content\": \"This is a meeting transcript.\"},\n",
    "      {\"role\": \"assistant\", \"content\": everything},\n",
    "      {\"role\": \"user\", \"content\": prompt},\n",
    "  ],\n",
    "  \"temperature\": 0.2\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=data).json()\n",
    "\n",
    "print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf74813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dazhi is bad according to the transcript.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
