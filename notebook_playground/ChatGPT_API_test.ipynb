{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aa82869",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import openai\n",
    "import webvtt\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b70e08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = \"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\"\n",
    "vtt_file = 'transcripts/jeffrey_working.vtt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e7e9b",
   "metadata": {},
   "source": [
    "# Proproces the transcripts and define the action items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "eb72c2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = []\n",
    "everything = \"\"\n",
    "for caption in webvtt.read(vtt_file):\n",
    "    everything += caption.text + \"\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35bdf988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Vincent: Hi, Jeffrey, and you need let's talk about the data screening project that you guys have of the project coming along.\\nJeffrey Feng: Hi, do you?\\nJeffrey Feng: We are a bit stuck with scraping some of the websites on our list. Some of them are dynamic, and I couldn't get the data we need.\\nYooni Choi: Yeah, and i'm new to this tax. So I was wondering if you could help us out.\\nVincent: Of course I will be happy to help. What specifically do you need help with.\\nJeffrey Feng: Well, many websites seem dynamic.\\nJeffrey Feng: so I was not able to figure out what to do if you scrape them. I used a few python libraries, but they are not returning me. What I want\\nVincent: have you read into the library?\\nJeffrey Feng: I have not.\\nVincent: Selenium is a software, testing framework used to all the main web browsers. They can similarly user interactions with with the website and from automated testing to check for error\\nVincent: performance issues and functionality twice for some of the website you were talking about.\\nJeffrey Feng: Sure, my first action item will be\\nJeffrey Feng: to read Selenium's documentation, then\\nYooni Choi: so, Jeffrey, have you been using the beautiful soup library.\\nJeffrey Feng: Yes, that's one of the Python libraries that I've been using.\\nYooni Choi: I kept having installation issues. I don't know what is the issue. My, My my python version might be too old.\\nJeffrey Feng: I'll help you with that. I guess another of my action item would be to help you with installation issues.\\nJeffrey Feng: Could you update your python environment before that\\nYooni Choi: that'd be great. Thank you. I'll update my python environment as my action. Item.\\nVincent: Well, you are waiting for Jeffrey to help you. I think you can read it in your beautiful soups. Documentation\\nYooni Choi: sounds good to me. I will make sure to read beautiful Soups documentation as my second action. Item.\\nVincent: Good, Jeffrey, could you create a kid up branch? So we can. In fact, the progress of this project.\\nJeffrey Feng: Sure, I can do that. My new action item is to create a Github branch. Then\\nVincent: another action item for both of you, Jeffrey, and a unique is to report the progress tomorrow to me again.\\nJeffrey Feng: Sure\\nYooni Choi: sounds good to me, Jeffrey. Could we schedule a meeting later? So you can explain your previous code to me. I want to make sure I understand it.\\nJeffrey Feng: Yeah, that sounds good. I will schedule a meeting with you as another action item of my\\nVincent: all right, great. And for Touches action. Item, I will also add a new member to our team to help us with this project.\\nVincent: I will send you all updating a week.\\nYooni Choi: Thanks, Dr.\\n\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cd02788",
   "metadata": {},
   "outputs": [],
   "source": [
    "agenda_items = \"1. Duke and Duchess of Sussex asked to vacate UK home Frogmore Cottage.\\\n",
    "2. Alex Muradugh guilty.\\\n",
    "3. Data Centers Intro/definition and origins/size, density and efficiency growth.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebbfccd",
   "metadata": {},
   "source": [
    "# Using langchain to break our meeting transcript into chunks and call OpenAI's API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07dc8312",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "llm = OpenAI(model_name=\"gpt-3.5-turbo-0301\", openai_api_key = API_KEY)\n",
    "\n",
    "source_chunks = []\n",
    "splitter = RecursiveCharacterTextSplitter()\n",
    "for chunk in splitter.split_text(everything):\n",
    "    source_chunks.append(Document(page_content=chunk))\n",
    "search_index = FAISS.from_documents(source_chunks, OpenAIEmbeddings(openai_api_key = API_KEY))\n",
    "\n",
    "chain = load_qa_chain(llm)\n",
    "\n",
    "def print_answer(question):\n",
    "    print(\n",
    "        chain(\n",
    "            {\n",
    "                \"input_documents\": search_index.similarity_search(question, k=4),\n",
    "                \"question\": question,\n",
    "            },\n",
    "            return_only_outputs=True,\n",
    "        )[\"output_text\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f99344d",
   "metadata": {},
   "source": [
    "# Action items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18f6de91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Dazhi Peng needs to work on the details of how much was paid for the renovation of Frogmore Cottage and present it at the next meeting. 2. Jiahe Feng needs to prepare a summary of Alex Murdough's charges and verdicts and have it ready within a week. 3. Jiahe Feng needs to prepare a diagram of the Lyrical design of data centers and share it with the team.\n"
     ]
    }
   ],
   "source": [
    "print_answer(\"Given the agenda items in this meeting transcript: \" + agenda_items + \"Can you identify the action items related to each of them?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "727620fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Finalize how much was paid for the refurbishment of Rockmore Cottage (DAZHI PENG and Jiahe Feng).\n",
      "2. Prepare a brief diagram of the design of a data center (DAZHI PENG).\n",
      "3. Watch a show and share thoughts on it (Jiahe Feng). \n",
      "4. Provide a summary of Alex Myrtle's charges and verdicts in a week (DAZHI PENG).\n"
     ]
    }
   ],
   "source": [
    "print_answer(\"What are the action items in this meeting transcript?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0904ad7f",
   "metadata": {},
   "source": [
    "# Agenda items\n",
    "ChatGPT can provide a very good summary of the content related to a specific agenda item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "779d422e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes. Yooni Choi mentions being busy with cloud work that is still ongoing and discusses the importance of understanding the physical resources that make up the cloud when programming for it. Jiahe Feng talks about the advancements in processing power, memory, and storage in data centers, as well as the increasing power and cooling requirements for large data centers. They do not go into great detail about specific cloud computing topics or projects they are working on.\n"
     ]
    }
   ],
   "source": [
    "print_answer(\"Can you provide more detail in this meeting transcript related to the cloud computing agenda item?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e8b329",
   "metadata": {},
   "source": [
    "# (Deprecated) Demo Test using OpenAI Native API\n",
    "Failed because each input can only accept at most 4096 tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ed95360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://api.openai.com/v1/chat/completions'\n",
    "# headers = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + API_KEY}\n",
    "# data = {\n",
    "#   \"model\": \"gpt-3.5-turbo\",\n",
    "#   \"messages\": [\n",
    "#       {\"role\": \"system\", \"content\": \"This is a meeting transcript.\"},\n",
    "#       {\"role\": \"assistant\", \"content\": \"Jeffrey: I am good. \\n Dazhi: I am bad.\"},\n",
    "#       {\"role\": \"user\", \"content\": \"Given the transcript, who is bad?\"},\n",
    "#   ],\n",
    "#   \"temperature\": 0.2\n",
    "# }\n",
    "\n",
    "# response = requests.post(url, headers=headers, json=data).json()\n",
    "\n",
    "# print(response['choices'][0]['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf74813a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dazhi is bad according to the transcript.\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38]",
   "language": "python",
   "name": "conda-env-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
